import sys
sys.modules["torch.classes"] = None

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler

from data_prep import prepare_data

# D√©finition du mod√®le
class ChurnModel(nn.Module):
    def __init__(self, input_dim):
        super(ChurnModel, self).__init__()
        self.fc1 = nn.Linear(input_dim, 128)
        self.dropout1 = nn.Dropout(0.5)
        self.fc2 = nn.Linear(128, 64)
        self.dropout2 = nn.Dropout(0.5)
        self.fc3 = nn.Linear(64, 32)
        self.fc4 = nn.Linear(32, 16)
        self.fc5 = nn.Linear(16, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.dropout1(x)
        x = torch.relu(self.fc2(x))
        x = self.dropout2(x)
        x = torch.relu(self.fc3(x))
        x = torch.relu(self.fc4(x))
        x = self.sigmoid(self.fc5(x))
        return x

# Fonction d'entra√Ænement
def train_model(X_train, y_train, batch_size=64, learning_rate=0.001, epochs=200, patience=10, model_path="churn_model.pth"):
    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)
    
    dataset = TensorDataset(X_train_tensor, y_train_tensor)
    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    
    model = ChurnModel(X_train.shape[1])
    criterion = nn.BCELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    best_loss = float('inf')
    patience_counter = 0



    if "loss_values" not in st.session_state:
        st.session_state["loss_values"] = []
    if "accuracy_values" not in st.session_state:
        st.session_state["accuracy_values"] = []
    if "plot_fig" not in st.session_state or st.session_state["plot_fig"] is None:
        st.session_state["plot_fig"] = plt.figure(figsize=(8, 5))

    

    loss_values = st.session_state["loss_values"]
    accuracy_values = st.session_state["accuracy_values"]


    plot_placeholder = st.empty()

    
    if st.session_state["plot_fig"] is not None:
        plot_placeholder.pyplot(st.session_state["plot_fig"])

    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        
        for data, target in train_loader:
            optimizer.zero_grad()
            outputs = model(data)
            loss = criterion(outputs, target)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            
            predicted = (outputs > 0.5).float()
            correct += (predicted == target).sum().item()
            total += target.size(0)
        
        avg_loss = running_loss / len(train_loader)
        accuracy = correct / total

        loss_values.append(avg_loss)
        accuracy_values.append(accuracy)

        fig, ax = plt.subplots(figsize=(8, 5))
        ax.plot(loss_values, label='Loss', color="blue")
        ax.plot(accuracy_values, label="Accuracy", color="orange")
        ax.set_xlabel("Epoch")
        ax.set_ylabel("Value")
        ax.set_title("Evolution des valeurs de loss et accuracy pendant l'entra√Ænement")
        ax.legend()
        
        st.session_state["plot_fig"] = fig
        plot_placeholder.pyplot(st.session_state["plot_fig"])


        if avg_loss < best_loss:
            best_loss = avg_loss
            patience_counter = 0
            torch.save(model.state_dict(), model_path)
        else:
            patience_counter += 1
            if patience_counter >= patience:
                st.write("Early stopping d√©clench√©")
                break
    
    return model

# Fonction de pr√©diction
def predict_churn(model_path="churn_model.pth", X_test=None):
    model = ChurnModel(X_test.shape[1])
    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
    model.eval()

    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
    with torch.no_grad():
        predictions = model(X_test_tensor).numpy()
        predictions = (predictions > 0.5).astype(int)
    
    return np.where(predictions == 1, "Yes", "No")

#Interface Streamlit
st.markdown("""
    <h1 style="text-align: center;">üîçüìä Pr√©diction de churn sur une client√®le d√©finie</h1>
""", unsafe_allow_html=True)

st.image("./image/churn_telecom_pic.png", caption="Source : Churn Analysis - Analytics Vidhya")

st.markdown("""
<style>
.intro-box {
    background-color: #e6e6fa;
    padding: 15px;
    border-radius: 10px;
    box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    font-size: 16px;
    line-height: 1.6;
    margin-bottom: 35px;
}
</style>

<div class="intro-box">
    <p>Ce projet vise √† anticiper le d√©part des clients d'une entreprise en analysant leurs comportements ainsi que leurs donn√©es transactionnelles. Il permet l'identification de clients √† risque de d√©part, de d√©terminer les facteurs influen√ßant leur fid√©lisation gr√¢ce √† l'analyse de corr√©lation des variables mais aussi d'aider les entreprises √† prendre des d√©cisions strat√©giques afin de r√©duire et/ou pr√©venir le taux de r√©siliation.</p>  
    <p>Les pr√©dictions sont effectu√©es √† partir d'un fichier CSV.<br>Notre mod√®le utilise un r√©seau de neurones et a obtenu un score maximal de <b>0.76</b> d'accuracy sur nos donn√©es de test.</p>  
</div>
""", unsafe_allow_html=True)


train_file = st.file_uploader("Chargez le fichier d'entra√Ænement (Votre dataset annot√© au format CSV)", type=["csv"])
if train_file is not None:
    df_train = pd.read_csv(train_file)

    if st.checkbox("Afficher un aper√ßu du dataset"):
        st.write(df_train.head())

    df_train = prepare_data(df_train)
    X_train = df_train.drop(columns=['Churn', 'customerID'])
    y_train = df_train['Churn']
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train.select_dtypes(include=['float64', 'int64']))

    if "correlation_fig" in st.session_state:
        st.subheader("Matrice de corr√©lation entre Churn et autres cat√©gories")
        st.pyplot(st.session_state["correlation_fig"])

    # Bouton d'entra√Ænement du mod√®le
    if st.button("Entra√Æner le mod√®le"):
        with st.spinner("Entra√Ænement en cours..."):
            model = train_model(X_train_scaled, y_train)
        st.success("Mod√®le entra√Æn√© avec succ√®s !")

        # G√©n√©ration de la heatmap et stockage dans session_state
        if train_file is not None:
            df_corr = df_train.select_dtypes(include=['float64', 'int64'])
            df_corr["Churn"] = y_train.replace({"Yes": 1, "No": 0})

            fig, ax = plt.subplots(figsize=(12, 6))
            sns.heatmap(df_corr.corr(), annot=True, cmap="coolwarm", fmt=".2f", ax=ax)
            st.session_state["correlation_fig"] = fig 
            st.subheader("Matrice de corr√©lation entre Churn et autres cat√©gories")
            st.pyplot(fig)
    

# Chargement des donn√©es de test
st.subheader("Faire des pr√©dictions sur vos donn√©es non annot√©es")
test_file = st.file_uploader("Chargez le fichier sur lequel faire des pr√©dictions (CSV)", type=["csv"], key="test")

if test_file is not None:
    df_test = pd.read_csv(test_file)
    df_test.set_index("customerID", inplace=True)
    X_test = df_test.select_dtypes(include=['float64', 'int64'])
    X_test_scaled = scaler.transform(X_test)

    # Bouton pour lancer la pr√©diction
    if st.button("Lancer les pr√©dictions"):
        predictions = predict_churn(X_test=X_test_scaled)
        df_test["Churn_Predicted"] = predictions
        st.session_state["df_predictions"] = df_test

    # Affichage des pr√©dictions si elles existent
    if "df_predictions" in st.session_state:
        st.subheader("Pr√©dictions enregistr√©es")
        st.dataframe(st.session_state["df_predictions"])

        # Bouton de t√©l√©chargement
        csv = st.session_state["df_predictions"].to_csv(index=False).encode('utf-8')
        st.download_button("T√©l√©charger le fichier avec les pr√©dictions", csv, "predictions.csv", "text/csv")

        # Recherche d'un client sp√©cifique
        st.subheader("Rechercher un client sp√©cifique")
        client_id = st.text_input("Entrez l'ID du client")

        if client_id:
            df_predictions = st.session_state["df_predictions"]
            if client_id in df_predictions.index:
                st.write("Donn√©es du client :")
                st.dataframe(df_predictions.loc[[client_id]])

                churn_status = df_predictions.loc[client_id, "Churn_Predicted"]
                st.write(f"Pr√©diction :")
                if churn_status == "Yes":
                    st.warning("**Yes** - ce client est un **churner**.")
                else:
                    st.success("**No** - ce client est un **non-churner**.")

                st.markdown("""
                ### ‚ÑπÔ∏è **Interpr√©tation des r√©sultats**
                - Si le statut est **'No'**, le client est **non-churner** (il reste abonn√©).
                - Si le statut est **'Yes'**, le client est **churner** (il risque de partir).  
                            
                Pour avoir plus de d√©tails sur les motivations des clients, r√©f√©rez-vous au **graphique de corr√©lation** en haut de page.  
                
                **Lecture de la corr√©lation :**            
                Plus une valeur est proche de **1** ou **-1**, plus la corr√©lation est forte.  
                exemple : si √† l'intersection de 'Churn' et 'tenure', la valeur est de -0.41, la corr√©lation est n√©gative et plut√¥t forte. Cela signifie que plus un client est fid√®le, moins il y a de churn.
                """)
            else:
                st.error("‚ùå Client introuvable.")
