# Projet r√©seaux de neurones - M2 TAL  
Marie Delporte-Landat & Clotilde L√©vy

## 1. Objectifs du projet  
Ce projet a pour objectif de pr√©dire le d√©part des clients d'une entreprise en analysant leurs donn√©es transactionnelles et comportementales.  
L'int√©r√™t est donc de pouvoir identifier les clients suceptibles de r√©silier le service, de d√©terminer les facteurs qui causent le d√©part _(cf. analyse des corr√©lations)_ et, par la suite, de pouvoir pr√©venir ces risques de d√©part.  

Notre projet est bas√© sur un mod√®le de r√©seau de neurones qui est entra√Æn√© sur un ensemble de donn√©es clients et int√©gr√© √† une interface interactive Streamlit. 

## 2. Dataset
Pour r√©aliser ce projet, nous avons utilis√© le dataset [**Teleco Customer Churn**](https://www.kaggle.com/datasets/blastchar/telco-customer-churn), disponible publiquement sur la plateforme Kaggle.

Il est au format CSV, et chaque ligne correspond √† un client et contient diverses informations sur ce dernier _(21 caract√©ristiques au total)_, notamment :  
- les **informations g√©n√©rales du client** : identifiant, sexe, √¢ge, pr√©sence d'un partenaire ou de personnes √† charge  
- les **donn√©es d'abonnement** : type de contrat, dur√©e d'engagement, mode de facturation et de paiement  
- les **services souscrits** : type de connexion internet, acc√®s aux services additionnels (t√©l√©phone, streaming, protection des appareils, support technique)  
- la **facturation** : co√ªt de l'abonnement, montant total factur√© depuis l'inscription  
- le **churn** qui constitue notre variable √† pr√©dire indiquant si le client va quitter ou non l'entreprise  

### Preprocessing du dataset
Avant d'entra√Æner notre mod√®le, nous avons proc√©d√© √† un r√©√©quilibrage des classes **Churn = Yes** et **Churn = No**, puisque notre dataset initial pr√©sentait un d√©s√©quilibre entre les clients ayant r√©sili√© leur abonnement et ceux l'ayant conserv√©.  
Pour corriger cela, nous avons appliqu√© une m√©thode de **sur-√©chantillonage** de la classe minoritaire afin d'obtenir une r√©partition √©quilibr√©e de nos donn√©es et ainsi √©viter que le mod√®le ne soit biais√© en faveur de la classe majoritaire.  


## 3. M√©thodologie
Voici la mani√®re dont nous avons proc√©d√© pour construire notre projet :  
- s√©lection d'un dataset sp√©cialement constitu√© pour de l'analyse et pr√©diction de churn
- observation des donn√©es
- test de m√©thodes de r√©√©quilibrage des classes afin d'obtenir des r√©sultats √©quilibr√©s
- test de mod√®les de r√©seaux de neurones
- impl√©mentation du meilleur mod√®le
- impl√©mentation de l'interface streamlit
- lier le mod√®le neuronal √† l'interface streamlit  

Nous avons travaill√© simultan√©ment sur les diff√©rentes √©tapes du projet dans le but d'obtenir la meilleure m√©thode de pr√©paration des donn√©es et meilleur mod√®le.  
Nous n'avons pas rencontr√© de difficult√© particuli√®re sur l'impl√©mentation du mod√®le.  
Les difficult√©s sont arriv√©es lorsque nous souhaitions lier le mod√®le √† l'interface streamlit.  
De plus streamlit √©tant une interface dynamique, d√®s que l'utilisateur interagit avec l'application, tous les graphiques et tableaux disparaissent. Il a donc fallu beaucoup jouer avec l'outil ```st.session_state``` pour r√©soudre ces probl√®mes.  



## 4. Impl√©mentation
Notre impl√©mentation du projet s'est r√©parti en plusieurs parties :  
- observation du dataset dans un notebook (non fourni) pour comprendre les donn√©es, la r√©partition des deux classes √† pr√©dire, des tests de diff√©rentes m√©thodes de r√©√©quilibrage des classes
- plusieurs impl√©mentations de mod√®les neuronaux test√©s pour obtenir la meilleure accuracy
- impl√©mentation d'un script python ex√©cutable en ligne de commande ```churn_model_with_testpred.py```
- impl√©mentation d'une interface web avec streamlit ```churn_app.py```


## 5. Utilisation des scripts et donn√©es
Voici ce qu'il faut savoir pour utiliser nos scripts et l'interface streamlit.  

Deux options sont possibles :  

- utiliser le script ```churn_model_with_testpred.py``` pour tester le mod√®le en ligne de commande.  
Ce script sert **uniquement** √† tester l'efficacit√© et les r√©sultats de notre mod√®le en faisant l'entrainement sur notre dataset de train, puis de le tester sur notre dataset de test. **Pour lancer les pr√©dictions sur vos propres donn√©es, r√©f√©rez-vous √† la partie sur l'interface streamlit.** Une fois les pr√©dictions termin√©es, le fichier de pr√©dictions g√©n√©r√© est directement compar√© aux valeurs r√©elles. Ce script permet de suivre l'entrainement, faire les pr√©dictions sur un fichier de test non annot√©, sauvegarder les pr√©dictions, afficher les r√©sultats du mod√®le en comparant les pr√©dictions aux valeurs r√©elles.  
Pour lancer ce script : 
> python3 churn_model_with_testpred.py   

Le fichier d'entrainement et de test avec les valeurs r√©elles sont directement dans le script. Il faudra seulement mentionner le fichier de test sur lequel faire les pr√©dictions ici :  

>  üëâ Entrez le chemin du fichier test : data/Telco-Customer-Churn_test.csv  

- utiliser le script ```churn_app.py``` avec l'interface streamlit.  
Ici, tout se passe dans l'interface web.  
Au d√©but, vous devrez d√©poser votre fichier d'entrainement au format CSV (```fichier ./data/Telco-Customer-Churn_train.csv pour nous```) puis laissez-vous guider par les diff√©rents boutons de l'interface.  
Il sera possible d'afficher un aper√ßu de votre dataset, lancer l'entrainement du mod√®le. Ensuite une matrice de corr√©lation s'affiche, mais il faudra s'y r√©f√©rer apr√®s les pr√©dictions faites (*tout est expliqu√© sur l'interface*).  

Ensuite, vous devrez d√©poser votre fichier de test au format CSV **non annot√©** (```fichier ./data/Telco-Customer-Churn_test.csv pour nous```) puis cliquez sur **_Lancer les pr√©dictions_**.  
Ensuite, vous pourrez t√©l√©charger les pr√©dictions au format CSV et faire des recherches sur un client sp√©cifique en rentrant sont *customerID*.  
Une fois un ID rentr√©, les donn√©es du client s'affichent puis la pr√©diction qui lui est associ√©e, ainsi que des explication permettant de comprendre les r√©sultats.  


## 6. R√©sultats & discussion
Notre mod√®le de pr√©diction de churn sur des donn√©es clients obtient un meilleur r√©sultat de **0.74 d'accuracy** par rapport √† notre dataset d'entrainement et de test.  
Pour utiliser notre interface, il est n√©cessaire d'avoir un dataset d√©j√† form√© avec une partie annot√©e et une non annot√©e. Pour l'utilisateur, l'int√©r√™t est d'avoir une quantit√© limit√©e de donn√©es annot√©es et √† travers notre mod√®le, de faire des pr√©dictions sur d'autres clients. L'avantage est qu'il n'aura pas besoin d'avoir le m√™me dataset que celui sur lequel nous avons travaill√© avec exactement les m√™mes colonnes, ce qui rend notre application g√©n√©ralisable.  
Concernant les perspectives d'am√©lioration, nous souhaiterions trouver un moyen d'afficher des explications plus pr√©cises qu'une analyse de corr√©lation sur pourquoi le client souhaite continuer de souscrire aux services ou partir. Nous avons fait des tests avec la library *Shap* qui permet d'expliquer les sorties d'un mod√®le de Machine Learning ou R√©seaux de Neurones, mais nous ne sommes pas parvenues √† l'impl√©menter correctement pour avoir des r√©sultats coh√©rent.  